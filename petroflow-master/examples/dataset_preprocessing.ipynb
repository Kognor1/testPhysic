{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from shutil import copytree\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lasio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATASET_PATH = \"/path/to/raw/dataset/\"\n",
    "PROCESSED_DATASET_PATH = \"/path/to/processed/dataset/\"\n",
    "FIELD = \"Field\"\n",
    "WELL_LIST = [\"well_1\", \"well_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fes = pd.read_excel(os.path.join(RAW_DATASET_PATH, \"FES_.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_well(well_name, dump_path):\n",
    "    dump_path = os.path.join(dump_path, well_name)\n",
    "    if not os.path.exists(dump_path):\n",
    "        os.makedirs(dump_path)\n",
    "\n",
    "    las = lasio.read(os.path.join(RAW_DATASET_PATH, well_name, \"logs.las\"))\n",
    "    logs = las.df().reset_index().set_index(\"DEPTH\")\n",
    "    logs.reset_index().to_feather(os.path.join(dump_path, \"logs.feather\"))\n",
    "    \n",
    "    meta = {\n",
    "        \"name\": well_name,\n",
    "        \"field\": FIELD,\n",
    "        \"depth_from\": las.header[\"Well\"][\"STRT\"].value,\n",
    "        \"depth_to\": las.header[\"Well\"][\"STOP\"].value,\n",
    "    }\n",
    "    with open(os.path.join(dump_path, \"meta.json\"), \"w\") as f:\n",
    "        json.dump(meta, f)\n",
    "\n",
    "    layers = pd.read_csv(os.path.join(RAW_DATASET_PATH, well_name, \"layers.csv\"), sep=\";\", encoding=\"cp1251\")\n",
    "    layers = (layers[[\"DEPTH_FROM\", \"DEPTH_TO\", \"LAYER\"]].round({\"DEPTH_FROM\": 2, \"DEPTH_TO\": 2})\n",
    "                                                         .drop_duplicates()\n",
    "                                                         .sort_values(by=[\"DEPTH_FROM\"])\n",
    "                                                         .set_index([\"DEPTH_FROM\", \"DEPTH_TO\"])\n",
    "    )\n",
    "    layers.reset_index().to_feather(os.path.join(dump_path, \"layers.feather\"))\n",
    "    \n",
    "    inclination = pd.read_csv(os.path.join(RAW_DATASET_PATH, well_name, \"inclination.csv\"), sep=\";\")\n",
    "    inclination.reset_index(drop=True).to_feather(os.path.join(dump_path, \"inclination.feather\"))\n",
    "\n",
    "    well_fes = fes[(fes[\"Well\"] == well_name) & (fes[\"Sheet\"] != \"Лист1\")]\n",
    "\n",
    "    core_properties = well_fes[[\"Глубина, м\", \"Пористость, %\", \"Прониц_парал.txt\"]]\n",
    "    core_properties.columns = [\"DEPTH\", \"POROSITY\", \"PERMEABILITY\"]\n",
    "    core_properties = core_properties.round({\"DEPTH\": 2}).sort_values(by=[\"DEPTH\"]).set_index(\"DEPTH\")\n",
    "    core_properties.reset_index().to_feather(os.path.join(dump_path, \"core_properties.feather\"))\n",
    "\n",
    "    boring_intervals = well_fes[[\"2_Верх_интервала.txt\", \"3_Низ_интервала.txt\", \"5_Вынос.txt\"]]\n",
    "    boring_intervals.columns = [\"DEPTH_FROM\", \"DEPTH_TO\", \"CORE_RECOVERY\"]\n",
    "    boring_intervals = (boring_intervals.round({\"DEPTH_FROM\": 2, \"DEPTH_TO\": 2})\n",
    "                                        .drop_duplicates()\n",
    "                                        .sort_values(by=[\"DEPTH_FROM\"])\n",
    "                                        .set_index([\"DEPTH_FROM\", \"DEPTH_TO\"])\n",
    "    )\n",
    "    boring_intervals.reset_index().to_feather(os.path.join(dump_path, \"boring_intervals.feather\"))\n",
    "\n",
    "    core_logs = pd.read_excel(os.path.join(RAW_DATASET_PATH, \"Привязка\", well_name + \".xls\"), header=2)[2:]\n",
    "    core_logs = core_logs[[\"Глубина до привязки, м\", \"Общая радиоактивность, API\", \"Объемная плотность, г/см3\"]]\n",
    "    core_logs.columns = [\"DEPTH\", \"GK\", \"DENSITY\"]\n",
    "    core_logs = (core_logs.round({\"DEPTH\": 2})\n",
    "                          .sort_values(by=[\"DEPTH\"])\n",
    "                          .set_index(\"DEPTH\")\n",
    "    )\n",
    "    core_logs.reset_index().to_feather(os.path.join(dump_path, \"core_logs.feather\"))\n",
    "\n",
    "    samples = pd.read_csv(os.path.join(RAW_DATASET_PATH, well_name, \"samples.csv\"), sep=\";\", encoding=\"cp1251\")\n",
    "    samples = samples[[\"DEPTH_FROM\", \"DEPTH_TO\", \"SAMPLE\", \"PHOTO QC\"]]\n",
    "    samples.columns = [\"DEPTH_FROM\", \"DEPTH_TO\", \"SAMPLE\", \"QC\"]\n",
    "    samples = (samples.round({\"DEPTH_FROM\": 2, \"DEPTH_TO\": 2})\n",
    "                      .sort_values(by=[\"DEPTH_FROM\"])\n",
    "                      .set_index([\"DEPTH_FROM\", \"DEPTH_TO\"])\n",
    "    )\n",
    "    samples.reset_index().to_feather(os.path.join(dump_path, \"samples.feather\"))\n",
    "\n",
    "    if os.path.exists(os.path.join(RAW_DATASET_PATH, well_name, \"samples_dl\")):\n",
    "        copytree(os.path.join(RAW_DATASET_PATH, well_name, \"samples_dl\"),\n",
    "                 os.path.join(dump_path, \"samples_dl\"))\n",
    "\n",
    "    if os.path.exists(os.path.join(RAW_DATASET_PATH, well_name, \"samples_uv\")):\n",
    "        copytree(os.path.join(RAW_DATASET_PATH, well_name, \"samples_uv\"),\n",
    "                 os.path.join(dump_path, \"samples_uv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for well_name in WELL_LIST:\n",
    "    process_well(well_name, PROCESSED_DATASET_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
